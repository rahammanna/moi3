{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes = 2\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:30.689563Z","iopub.execute_input":"2022-05-17T09:29:30.690129Z","iopub.status.idle":"2022-05-17T09:29:33.476094Z","shell.execute_reply.started":"2022-05-17T09:29:30.690096Z","shell.execute_reply":"2022-05-17T09:29:33.475113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:33.478092Z","iopub.execute_input":"2022-05-17T09:29:33.478528Z","iopub.status.idle":"2022-05-17T09:29:33.491595Z","shell.execute_reply.started":"2022-05-17T09:29:33.478494Z","shell.execute_reply":"2022-05-17T09:29:33.490597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n\n\ntrain_generator = data_generator.flow_from_directory(\n        '../input/indoorsoutdoors',\n        target_size=(image_size, image_size),\n        batch_size=15,\n        class_mode='categorical',\n        subset='training')\n\nvalidation_generator = data_generator.flow_from_directory(\n        '../input/indoorsoutdoors',\n        target_size=(image_size, image_size),\n        class_mode='categorical',\n        subset='validation')\n\nmy_new_model.fit_generator(\n        train_generator,\n        steps_per_epoch=40,\n        validation_data=validation_generator,\n        validation_steps=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:33.493306Z","iopub.execute_input":"2022-05-17T09:29:33.493605Z","iopub.status.idle":"2022-05-17T09:29:51.281387Z","shell.execute_reply.started":"2022-05-17T09:29:33.493545Z","shell.execute_reply":"2022-05-17T09:29:51.280808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os.path import join\n\nimage_dir = '../input/indoorsoutdoors/'\n\nimage_filenames = ['outdoors/1-park.jpg',\n                  'indoors/Indoor-Plants-Maui-Kentia-Palm.jpg',\n                  'indoors/in.jpg',\n                  'outdoors/out.jpg']\n\nimg_paths = [join(image_dir, filename) for filename in image_filenames ]\n\nimage_size = 224\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    \n    return(output)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:51.283572Z","iopub.execute_input":"2022-05-17T09:29:51.284077Z","iopub.status.idle":"2022-05-17T09:29:51.291998Z","shell.execute_reply.started":"2022-05-17T09:29:51.284033Z","shell.execute_reply":"2022-05-17T09:29:51.291374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = read_and_prep_images(img_paths)\n\npreds = my_new_model.predict(test_data)\n\npreds","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:51.293277Z","iopub.execute_input":"2022-05-17T09:29:51.293764Z","iopub.status.idle":"2022-05-17T09:29:53.015696Z","shell.execute_reply.started":"2022-05-17T09:29:51.29372Z","shell.execute_reply":"2022-05-17T09:29:53.014669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image, display\n\nfor i, img_path in enumerate(img_paths):\n    display(Image(img_path))\n    if preds[i][0] > preds[i][1]:\n        print(\"Indoors\")\n    else:\n        print(\"Outdoors\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T09:29:53.017092Z","iopub.execute_input":"2022-05-17T09:29:53.017305Z","iopub.status.idle":"2022-05-17T09:29:53.05515Z","shell.execute_reply.started":"2022-05-17T09:29:53.017278Z","shell.execute_reply":"2022-05-17T09:29:53.054158Z"},"trusted":true},"execution_count":null,"outputs":[]}]}